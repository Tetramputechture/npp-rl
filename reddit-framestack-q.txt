# Question about Frame Stacking and LSTMs in RL with Directly Observable States

I'm working on training an RL agent for a 2D platformer using a custom Gym environment. My environment has two types of observations:

1. **Directly Observable Game State:**
   - Entity positions
   - Velocities
   - Physics parameters (gravity, drag, friction)
   - All normalized and directly input to observation space

2. **Visual Observations:**
   - Localized view around the player (for pixel-level interactions)
   - Downsampled view of entire map
   
The action space is discrete with 6 possible actions per tick.

**My Questions:**
1. Given that all game state data is directly observable, is frame stacking still beneficial? Or is using just 1 frame of the localized view sufficient?
2. If I remove frame stacking, would an LSTM be appropriate here to maintain temporal information? 
3. If I do use frame stacking, should I stack both the localized player view AND the global map view, or just the player view? I'm wondering about the tradeoffs in terms of memory usage vs potential benefits.
4. For frame stacking, some implementations use intervals (current frame, 4th frame back, 8th frame back, 12th frame back) rather than consecutive frames. Given that I have direct state observations, would this interval approach still be beneficial, or should I use consecutive frames?
5. If using consecutive frames, what's the optimal number of frames to stack? I've seen implementations use anywhere from 2-8 frames.

I'm trying to understand the tradeoffs between these approaches given that I have perfect information about the game state at each timestep.

Thanks for any insights! 