Loading TensorBoard data from /workspace/npp-rl...
Found events file: /workspace/npp-rl/events.out.tfevents.1761502655.192-222-53-138.84948.1

Found 152 scalar metrics:
  - actions/entropy
  - actions/frequency/Jump
  - actions/frequency/Jump+Left
  - actions/frequency/Jump+Right
  - actions/frequency/Left
  - actions/frequency/NOOP
  - actions/frequency/Right
  - actions/jump/directional_pct
  - actions/jump/frequency
  - actions/jump/vertical_only_pct
  - actions/movement/active_pct
  - actions/movement/left_bias
  - actions/movement/right_bias
  - actions/movement/stationary_pct
  - actions/transitions/Jump+Left_to_Jump
  - actions/transitions/Jump+Left_to_Jump+Left
  - actions/transitions/Jump+Left_to_Jump+Right
  - actions/transitions/Jump+Left_to_Left
  - actions/transitions/Jump+Left_to_NOOP
  - actions/transitions/Jump+Left_to_Right
  - actions/transitions/Jump+Right_to_Jump
  - actions/transitions/Jump+Right_to_Jump+Left
  - actions/transitions/Jump+Right_to_Jump+Right
  - actions/transitions/Jump+Right_to_Left
  - actions/transitions/Jump+Right_to_NOOP
  - actions/transitions/Jump+Right_to_Right
  - actions/transitions/Jump_to_Jump
  - actions/transitions/Jump_to_Jump+Left
  - actions/transitions/Jump_to_Jump+Right
  - actions/transitions/Jump_to_Left
  - actions/transitions/Jump_to_NOOP
  - actions/transitions/Jump_to_Right
  - actions/transitions/Left_to_Jump
  - actions/transitions/Left_to_Jump+Left
  - actions/transitions/Left_to_Jump+Right
  - actions/transitions/Left_to_Left
  - actions/transitions/Left_to_NOOP
  - actions/transitions/Left_to_Right
  - actions/transitions/NOOP_to_Jump
  - actions/transitions/NOOP_to_Jump+Left
  - actions/transitions/NOOP_to_Jump+Right
  - actions/transitions/NOOP_to_Left
  - actions/transitions/NOOP_to_NOOP
  - actions/transitions/NOOP_to_Right
  - actions/transitions/Right_to_Jump
  - actions/transitions/Right_to_Jump+Left
  - actions/transitions/Right_to_Jump+Right
  - actions/transitions/Right_to_Left
  - actions/transitions/Right_to_NOOP
  - actions/transitions/Right_to_Right
  - curriculum/advancement_threshold
  - curriculum/can_advance
  - curriculum/current_stage_idx
  - curriculum/episodes_in_stage
  - curriculum/success_rate
  - curriculum_stages/complex_episodes
  - curriculum_stages/complex_success_rate
  - curriculum_stages/exploration_episodes
  - curriculum_stages/exploration_success_rate
  - curriculum_stages/medium_episodes
  - curriculum_stages/medium_success_rate
  - curriculum_stages/mine_heavy_episodes
  - curriculum_stages/mine_heavy_success_rate
  - curriculum_stages/simple_episodes
  - curriculum_stages/simple_success_rate
  - curriculum_stages/simpler_episodes
  - curriculum_stages/simpler_success_rate
  - curriculum_stages/simplest_episodes
  - curriculum_stages/simplest_success_rate
  - episode/failure_rate
  - episode/success_rate
  - gradients/features_extractor.fusion.0.bias_norm
  - gradients/features_extractor.fusion.0.weight_norm
  - gradients/features_extractor.fusion.3.bias_norm
  - gradients/features_extractor.fusion.3.weight_norm
  - gradients/features_extractor.global_cnn.conv_layers.0.bias_norm
  - gradients/features_extractor.global_cnn.conv_layers.0.weight_norm
  - gradients/features_extractor.global_cnn.conv_layers.1.bias_norm
  - gradients/features_extractor.global_cnn.conv_layers.1.weight_norm
  - gradients/features_extractor.global_cnn.conv_layers.4.bias_norm
  - gradients/features_extractor.global_cnn.conv_layers.4.weight_norm
  - gradients/features_extractor.global_cnn.conv_layers.5.bias_norm
  - gradients/features_extractor.global_cnn.conv_layers.5.weight_norm
  - gradients/features_extractor.global_cnn.conv_layers.8.bias_norm
  - gradients/features_extractor.global_cnn.conv_layers.8.weight_norm
  - gradients/features_extractor.global_cnn.conv_layers.9.bias_norm
  - gradients/features_extractor.global_cnn.conv_layers.9.weight_norm
  - gradients/features_extractor.global_cnn.fc.1.bias_norm
  - gradients/features_extractor.global_cnn.fc.1.weight_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.0.bias_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.0.weight_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.1.bias_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.1.weight_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.4.bias_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.4.weight_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.5.bias_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.5.weight_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.8.bias_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.8.weight_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.9.bias_norm
  - gradients/features_extractor.player_frame_cnn.conv_layers.9.weight_norm
  - gradients/features_extractor.player_frame_cnn.fc.1.bias_norm
  - gradients/features_extractor.player_frame_cnn.fc.1.weight_norm
  - gradients/features_extractor.reachability_mlp.0.bias_norm
  - gradients/features_extractor.reachability_mlp.0.weight_norm
  - gradients/features_extractor.reachability_mlp.2.bias_norm
  - gradients/features_extractor.reachability_mlp.2.weight_norm
  - gradients/features_extractor.state_mlp.mlp.0.bias_norm
  - gradients/features_extractor.state_mlp.mlp.0.weight_norm
  - gradients/features_extractor.state_mlp.mlp.3.bias_norm
  - gradients/features_extractor.state_mlp.mlp.3.weight_norm
  - gradients/mlp_extractor.policy_net.0.bias_norm
  - gradients/mlp_extractor.policy_net.0.weight_norm
  - gradients/mlp_extractor.policy_net.2.bias_norm
  - gradients/mlp_extractor.policy_net.2.weight_norm
  - gradients/mlp_extractor.policy_net.4.bias_norm
  - gradients/mlp_extractor.policy_net.4.weight_norm
  - gradients/mlp_extractor.value_net.0.bias_norm
  - gradients/mlp_extractor.value_net.0.weight_norm
  - gradients/mlp_extractor.value_net.2.bias_norm
  - gradients/mlp_extractor.value_net.2.weight_norm
  - gradients/mlp_extractor.value_net.4.bias_norm
  - gradients/mlp_extractor.value_net.4.weight_norm
  - gradients/total_norm
  - loss/entropy
  - loss/total
  - loss/value
  - performance/elapsed_time_minutes
  - performance/fps_instant
  - performance/fps_mean
  - performance/rollout_time_mean
  - performance/rollout_time_seconds
  - performance/steps_per_second
  - rollout/success_rate
  - time/fps
  - train/approx_kl
  - train/clip_fraction
  - train/clip_range
  - train/entropy_loss
  - train/explained_variance
  - train/learning_rate
  - train/loss
  - train/policy_gradient_loss
  - train/value_loss
  - training/approx_kl
  - training/clip_fraction
  - training/explained_variance
  - training/learning_rate
  - value/estimate_max
  - value/estimate_mean
  - value/estimate_min
  - value/estimate_std

================================================================================
CURRICULUM PROGRESSION ANALYSIS
================================================================================

=== Success Rates by Stage ===

curriculum/success_rate:
  Final: 0.040
  Max: 1.000
  Mean: 0.206

curriculum_stages/complex_success_rate:
  Final: 0.000
  Max: 0.000
  Mean: 0.000

curriculum_stages/exploration_success_rate:
  Final: 0.000
  Max: 0.000
  Mean: 0.000

curriculum_stages/medium_success_rate:
  Final: 0.000
  Max: 0.000
  Mean: 0.000

curriculum_stages/mine_heavy_success_rate:
  Final: 0.000
  Max: 0.000
  Mean: 0.000

curriculum_stages/simple_success_rate:
  Final: 0.040
  Max: 0.148
  Mean: 0.073

curriculum_stages/simpler_success_rate:
  Final: 0.680
  Max: 1.000
  Mean: 0.645

curriculum_stages/simplest_success_rate:
  Final: 1.000
  Max: 1.000
  Mean: 1.000

=== Stage Progression ===

curriculum/current_stage_idx:
  Initial: 1.0
  Final: 2.0
  Max reached: 2.0

curriculum/episodes_in_stage:
  Initial: 19.0
  Final: 435.0
  Max reached: 435.0

curriculum_stages/complex_episodes:
  Initial: 0.0
  Final: 0.0
  Max reached: 0.0

curriculum_stages/complex_success_rate:
  Initial: 0.0
  Final: 0.0
  Max reached: 0.0

curriculum_stages/exploration_episodes:
  Initial: 0.0
  Final: 0.0
  Max reached: 0.0

curriculum_stages/exploration_success_rate:
  Initial: 0.0
  Final: 0.0
  Max reached: 0.0

curriculum_stages/medium_episodes:
  Initial: 0.0
  Final: 0.0
  Max reached: 0.0

curriculum_stages/medium_success_rate:
  Initial: 0.0
  Final: 0.0
  Max reached: 0.0

curriculum_stages/mine_heavy_episodes:
  Initial: 0.0
  Final: 0.0
  Max reached: 0.0

curriculum_stages/mine_heavy_success_rate:
  Initial: 0.0
  Final: 0.0
  Max reached: 0.0

curriculum_stages/simple_episodes:
  Initial: 0.0
  Final: 435.0
  Max reached: 435.0

curriculum_stages/simple_success_rate:
  Initial: 0.0
  Final: 0.03999999910593033
  Max reached: 0.14814814925193787

curriculum_stages/simpler_episodes:
  Initial: 19.0
  Final: 485.0
  Max reached: 485.0

curriculum_stages/simpler_success_rate:
  Initial: 1.0
  Final: 0.6800000071525574
  Max reached: 1.0

curriculum_stages/simplest_episodes:
  Initial: 44.0
  Final: 122.0
  Max reached: 122.0

curriculum_stages/simplest_success_rate:
  Initial: 1.0
  Final: 1.0
  Max reached: 1.0

================================================================================
ACTION DISTRIBUTION ANALYSIS
================================================================================

Found 52 action-related metrics:

actions/entropy:
  Final: 1.7907
  Mean: 1.7899
  Std: 0.0011

actions/frequency/Jump:
  Final: 0.1659
  Mean: 0.1653
  Std: 0.0043

actions/frequency/Jump+Left:
  Final: 0.1600
  Mean: 0.1625
  Std: 0.0035

actions/frequency/Jump+Right:
  Final: 0.1807
  Mean: 0.1823
  Std: 0.0059

actions/frequency/Left:
  Final: 0.1704
  Mean: 0.1568
  Std: 0.0052

actions/frequency/NOOP:
  Final: 0.1561
  Mean: 0.1581
  Std: 0.0049

actions/frequency/Right:
  Final: 0.1669
  Mean: 0.1749
  Std: 0.0038

actions/jump/directional_pct:
  Final: 0.6726
  Mean: 0.6760
  Std: 0.0070

actions/jump/frequency:
  Final: 0.5066
  Mean: 0.5102
  Std: 0.0058

actions/jump/vertical_only_pct:
  Final: 0.3274
  Mean: 0.3240
  Std: 0.0070

actions/movement/active_pct:
  Final: 0.8439
  Mean: 0.8419
  Std: 0.0049

actions/movement/left_bias:
  Final: 0.4873
  Mean: 0.4720
  Std: 0.0104

actions/movement/right_bias:
  Final: 0.5127
  Mean: 0.5280
  Std: 0.0104

actions/movement/stationary_pct:
  Final: 0.1561
  Mean: 0.1581
  Std: 0.0049

actions/transitions/Jump+Left_to_Jump:
  Final: 0.1622
  Mean: 0.1633
  Std: 0.0057

actions/transitions/Jump+Left_to_Jump+Left:
  Final: 0.1788
  Mean: 0.1755
  Std: 0.0084

actions/transitions/Jump+Left_to_Jump+Right:
  Final: 0.1790
  Mean: 0.1807
  Std: 0.0056

actions/transitions/Jump+Left_to_Left:
  Final: 0.1641
  Mean: 0.1519
  Std: 0.0064

actions/transitions/Jump+Left_to_NOOP:
  Final: 0.1488
  Mean: 0.1541
  Std: 0.0065

actions/transitions/Jump+Left_to_Right:
  Final: 0.1672
  Mean: 0.1745
  Std: 0.0035

actions/transitions/Jump+Right_to_Jump:
  Final: 0.1635
  Mean: 0.1639
  Std: 0.0039

actions/transitions/Jump+Right_to_Jump+Left:
  Final: 0.1594
  Mean: 0.1610
  Std: 0.0040

actions/transitions/Jump+Right_to_Jump+Right:
  Final: 0.1986
  Mean: 0.1971
  Std: 0.0068

actions/transitions/Jump+Right_to_Left:
  Final: 0.1656
  Mean: 0.1524
  Std: 0.0052

actions/transitions/Jump+Right_to_NOOP:
  Final: 0.1523
  Mean: 0.1539
  Std: 0.0053

actions/transitions/Jump+Right_to_Right:
  Final: 0.1607
  Mean: 0.1717
  Std: 0.0063

actions/transitions/Jump_to_Jump:
  Final: 0.1846
  Mean: 0.1785
  Std: 0.0065

actions/transitions/Jump_to_Jump+Left:
  Final: 0.1564
  Mean: 0.1610
  Std: 0.0027

actions/transitions/Jump_to_Jump+Right:
  Final: 0.1805
  Mean: 0.1823
  Std: 0.0049

actions/transitions/Jump_to_Left:
  Final: 0.1666
  Mean: 0.1536
  Std: 0.0059

actions/transitions/Jump_to_NOOP:
  Final: 0.1516
  Mean: 0.1547
  Std: 0.0059

actions/transitions/Jump_to_Right:
  Final: 0.1602
  Mean: 0.1699
  Std: 0.0046

actions/transitions/Left_to_Jump:
  Final: 0.1620
  Mean: 0.1597
  Std: 0.0041

actions/transitions/Left_to_Jump+Left:
  Final: 0.1551
  Mean: 0.1599
  Std: 0.0046

actions/transitions/Left_to_Jump+Right:
  Final: 0.1765
  Mean: 0.1788
  Std: 0.0060

actions/transitions/Left_to_Left:
  Final: 0.1922
  Mean: 0.1724
  Std: 0.0067

actions/transitions/Left_to_NOOP:
  Final: 0.1512
  Mean: 0.1549
  Std: 0.0055

actions/transitions/Left_to_Right:
  Final: 0.1630
  Mean: 0.1743
  Std: 0.0052

actions/transitions/NOOP_to_Jump:
  Final: 0.1627
  Mean: 0.1642
  Std: 0.0047

actions/transitions/NOOP_to_Jump+Left:
  Final: 0.1530
  Mean: 0.1583
  Std: 0.0024

actions/transitions/NOOP_to_Jump+Right:
  Final: 0.1749
  Mean: 0.1765
  Std: 0.0065

actions/transitions/NOOP_to_Left:
  Final: 0.1661
  Mean: 0.1550
  Std: 0.0044

actions/transitions/NOOP_to_NOOP:
  Final: 0.1786
  Mean: 0.1740
  Std: 0.0070

actions/transitions/NOOP_to_Right:
  Final: 0.1647
  Mean: 0.1721
  Std: 0.0037

actions/transitions/Right_to_Jump:
  Final: 0.1601
  Mean: 0.1624
  Std: 0.0045

actions/transitions/Right_to_Jump+Left:
  Final: 0.1582
  Mean: 0.1596
  Std: 0.0036

actions/transitions/Right_to_Jump+Right:
  Final: 0.1730
  Mean: 0.1769
  Std: 0.0076

actions/transitions/Right_to_Left:
  Final: 0.1666
  Mean: 0.1563
  Std: 0.0056

actions/transitions/Right_to_NOOP:
  Final: 0.1558
  Mean: 0.1584
  Std: 0.0067

actions/transitions/Right_to_Right:
  Final: 0.1863
  Mean: 0.1864
  Std: 0.0076

train/clip_fraction:
  Final: 0.1647
  Mean: 0.1555
  Std: 0.0298

training/clip_fraction:
  Final: 0.1647
  Mean: 0.1555
  Std: 0.0296

================================================================================
PPO TRAINING METRICS ANALYSIS
================================================================================

=== Loss ===

loss/entropy:
  Initial: -1.785431
  Final: -1.713283
  Mean: -1.732819
  Std: 0.020793
  Change: 4.04%

loss/total:
  Initial: 0.098271
  Final: 0.335198
  Mean: 0.245025
  Std: 0.120052
  Change: 241.10%

loss/value:
  Initial: 0.384751
  Final: 0.601755
  Mean: 0.704704
  Std: 0.218663
  Change: 56.40%

train/entropy_loss:
  Initial: -1.785431
  Final: -1.713283
  Mean: -1.732819
  Std: 0.020944
  Change: 4.04%

train/loss:
  Initial: 0.098271
  Final: 0.335198
  Mean: 0.245025
  Std: 0.120924
  Change: 241.10%

train/policy_gradient_loss:
  Initial: -0.004230
  Final: -0.007859
  Mean: -0.007004
  Std: 0.001341
  Change: -85.79%

train/value_loss:
  Initial: 0.384751
  Final: 0.601755
  Mean: 0.704704
  Std: 0.220252
  Change: 56.40%

=== Entropy ===

actions/entropy:
  Initial: 1.753597
  Final: 1.790670
  Mean: 1.789874
  Std: 0.001087
  Change: 2.11%

loss/entropy:
  Initial: -1.785431
  Final: -1.713283
  Mean: -1.732819
  Std: 0.020793
  Change: 4.04%

train/entropy_loss:
  Initial: -1.785431
  Final: -1.713283
  Mean: -1.732819
  Std: 0.020944
  Change: 4.04%

=== Clipping ===

train/clip_fraction:
  Initial: 0.064314
  Final: 0.164662
  Mean: 0.155511
  Std: 0.029769
  Change: 156.03%

train/clip_range:
  Initial: 0.200000
  Final: 0.200000
  Mean: 0.200000
  Std: 0.000000
  Change: 0.00%

training/clip_fraction:
  Initial: 0.064314
  Final: 0.164662
  Mean: 0.155511
  Std: 0.029554
  Change: 156.03%

=== KL Divergence ===

train/approx_kl:
  Initial: 0.009458
  Final: 0.014417
  Mean: 0.014120
  Std: 0.002239
  Change: 52.43%

training/approx_kl:
  Initial: 0.009458
  Final: 0.014417
  Mean: 0.014120
  Std: 0.002223
  Change: 52.43%

=== Value ===

gradients/mlp_extractor.value_net.0.bias_norm:
  Initial: 0.003164
  Final: 0.001064
  Mean: 0.001733
  Std: 0.000892
  Change: -66.36%

gradients/mlp_extractor.value_net.0.weight_norm:
  Initial: 0.026040
  Final: 0.023204
  Mean: 0.039661
  Std: 0.012638
  Change: -10.89%

gradients/mlp_extractor.value_net.2.bias_norm:
  Initial: 0.002220
  Final: 0.002608
  Mean: 0.003004
  Std: 0.001281
  Change: 17.50%

gradients/mlp_extractor.value_net.2.weight_norm:
  Initial: 0.022454
  Final: 0.032992
  Mean: 0.044366
  Std: 0.019917
  Change: 46.93%

gradients/mlp_extractor.value_net.4.bias_norm:
  Initial: 0.001702
  Final: 0.002256
  Mean: 0.002928
  Std: 0.001263
  Change: 32.53%

gradients/mlp_extractor.value_net.4.weight_norm:
  Initial: 0.029737
  Final: 0.027771
  Mean: 0.039617
  Std: 0.014440
  Change: -6.61%

loss/value:
  Initial: 0.384751
  Final: 0.601755
  Mean: 0.704704
  Std: 0.218663
  Change: 56.40%

train/value_loss:
  Initial: 0.384751
  Final: 0.601755
  Mean: 0.704704
  Std: 0.220252
  Change: 56.40%

value/estimate_max:
  Initial: 0.390850
  Final: -0.305392
  Mean: 0.028739
  Std: 1.024677
  Change: -178.14%

value/estimate_mean:
  Initial: -0.061309
  Final: -4.332288
  Mean: -4.221129
  Std: 1.184234
  Change: -6966.33%

value/estimate_min:
  Initial: -0.458001
  Final: -7.350988
  Mean: -7.155573
  Std: 1.414669
  Change: -1505.01%

value/estimate_std:
  Initial: 0.194940
  Final: 1.762336
  Mean: 1.842997
  Std: 0.493144
  Change: 804.04%

=== Policy ===

gradients/mlp_extractor.policy_net.0.bias_norm:
  Initial: 0.001418
  Final: 0.000132
  Mean: 0.000434
  Std: 0.000389
  Change: -90.72%

gradients/mlp_extractor.policy_net.0.weight_norm:
  Initial: 0.006037
  Final: 0.004238
  Mean: 0.009613
  Std: 0.005045
  Change: -29.80%

gradients/mlp_extractor.policy_net.2.bias_norm:
  Initial: 0.000997
  Final: 0.000285
  Mean: 0.000686
  Std: 0.000356
  Change: -71.39%

gradients/mlp_extractor.policy_net.2.weight_norm:
  Initial: 0.003940
  Final: 0.004394
  Mean: 0.009557
  Std: 0.004881
  Change: 11.52%

gradients/mlp_extractor.policy_net.4.bias_norm:
  Initial: 0.000771
  Final: 0.000395
  Mean: 0.000841
  Std: 0.000422
  Change: -48.77%

gradients/mlp_extractor.policy_net.4.weight_norm:
  Initial: 0.003710
  Final: 0.005594
  Mean: 0.011224
  Std: 0.005920
  Change: 50.77%

train/policy_gradient_loss:
  Initial: -0.004230
  Final: -0.007859
  Mean: -0.007004
  Std: 0.001341
  Change: -85.79%

================================================================================
REWARD AND EPISODE ANALYSIS
================================================================================

=== Episode Statistics ===

curriculum/episodes_in_stage:
  Initial: 19.0000
  Final: 435.0000
  Mean: 193.4714
  Max: 435.0000
  Min: 0.0000

curriculum_stages/complex_episodes:
  Initial: 0.0000
  Final: 0.0000
  Mean: 0.0000
  Max: 0.0000
  Min: 0.0000

curriculum_stages/exploration_episodes:
  Initial: 0.0000
  Final: 0.0000
  Mean: 0.0000
  Max: 0.0000
  Min: 0.0000

curriculum_stages/medium_episodes:
  Initial: 0.0000
  Final: 0.0000
  Mean: 0.0000
  Max: 0.0000
  Min: 0.0000

curriculum_stages/mine_heavy_episodes:
  Initial: 0.0000
  Final: 0.0000
  Mean: 0.0000
  Max: 0.0000
  Min: 0.0000

curriculum_stages/simple_episodes:
  Initial: 0.0000
  Final: 435.0000
  Mean: 168.0143
  Max: 435.0000
  Min: 0.0000

curriculum_stages/simpler_episodes:
  Initial: 19.0000
  Final: 485.0000
  Mean: 311.6000
  Max: 485.0000
  Min: 19.0000

curriculum_stages/simplest_episodes:
  Initial: 44.0000
  Final: 122.0000
  Mean: 111.0714
  Max: 122.0000
  Min: 44.0000

episode/failure_rate:
  Initial: 0.0000
  Final: 0.7400
  Mean: 0.5687
  Max: 0.7900
  Min: 0.0000

episode/success_rate:
  Initial: 1.0000
  Final: 0.2600
  Mean: 0.4313
  Max: 1.0000
  Min: 0.2100

================================================================================
LEARNING RATE AND SCHEDULING ANALYSIS
================================================================================

train/learning_rate:
  Initial: 3.000000e-04
  Final: 3.000000e-04
  Schedule type: Constant

training/learning_rate:
  Initial: 3.000000e-04
  Final: 3.000000e-04
  Schedule type: Constant

================================================================================
EXPLORATION METRICS ANALYSIS
================================================================================

actions/entropy:
  Initial: 1.753597
  Final: 1.790670
  Mean: 1.789874
  Decrease: -2.11%

curriculum_stages/exploration_episodes:
  Initial: 0.000000
  Final: 0.000000
  Mean: 0.000000

curriculum_stages/exploration_success_rate:
  Initial: 0.000000
  Final: 0.000000
  Mean: 0.000000

loss/entropy:
  Initial: -1.785431
  Final: -1.713283
  Mean: -1.732819
  Decrease: 4.04%

train/entropy_loss:
  Initial: -1.785431
  Final: -1.713283
  Mean: -1.732819
  Decrease: 4.04%

================================================================================
CREATING VISUALIZATIONS
================================================================================
Saved: analysis_output/curriculum_progression.png
Saved: analysis_output/training_losses.png
Saved: analysis_output/entropy.png

================================================================================
GENERATING SUMMARY REPORT
================================================================================
Summary report saved to: analysis_output/summary_report.json

================================================================================
ANALYSIS COMPLETE
================================================================================

All results saved to 'analysis_output/' directory
